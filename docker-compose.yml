
# Общие переменные окружения для Airflow
x-airflow-environment: &airflow-env
  AIRFLOW__CORE__EXECUTOR: ${AIRFLOW_EXECUTOR}
  AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}
  AIRFLOW__CELERY__RESULT_BACKEND: db+postgresql://${DB_USER}:${DB_PASSWORD}@${DB_HOST}:${DB_PORT}/${DB_NAME}
  AIRFLOW__CELERY__BROKER_URL: redis://:@${REDIS_HOST}:${REDIS_PORT}/0
  AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY}

# Общая сеть для всех контейнеров
networks:
  airflow-net:
    external: true

# Volumes для хранения данных между перезапусками контейнеров
volumes:
  pgdata:          # Данные PostgreSQL (northwind-db)
  metabase_pgdata: # Данные PostgreSQL для метаданных Metabase
  dbt_profiles:    # Профили конфигурации DBT

services:

  # Инициализация Airflow и создание админа
  airflow-init:
      build:
        context: .  # папка с Dockerfile
        dockerfile: Dockerfile
      entrypoint: ""
      healthcheck:
        test: ["CMD-SHELL", "airflow db check"]
        interval: 10s
        retries: 5
        timeout: 10s
      command: ["sh","-c",
        "airflow db migrate && \
        airflow users create \
          --username ${AIRFLOW_ADMIN_USER} \
          --firstname ${AIRFLOW_ADMIN_FIRSTNAME} \
          --lastname ${AIRFLOW_ADMIN_LASTNAME} \
          --role ${AIRFLOW_ADMIN_ROLE} \
          --email ${AIRFLOW_ADMIN_EMAIL} \
          --password ${AIRFLOW_ADMIN_PASSWORD} \
        || true && \
        airflow connections add postgres_conn \
          --conn-type postgres \
          --conn-host northwind-db \
          --conn-login ${DB_USER} \
          --conn-password ${DB_PASSWORD} \
          --conn-port 5432 \
          --conn-schema ${DB_NAME} \
        || true"
      ]
      environment:
        <<: *airflow-env
        DB_USER: ${DB_USER}
        DB_PASSWORD: ${DB_PASSWORD}
        DB_NAME: ${DB_NAME}
      # user: "0:0"   # ← не нужно! иначе airflow не найдётся в PATH
      volumes:
        - ./dags:/opt/airflow/dags
        - ./logs:/opt/airflow/logs
        - ./plugins:/opt/airflow/plugins
        - ./dbt:/usr/app         # dbt проект
        - ./requirements.txt:/usr/app/requirements.txt:ro
      networks:
        - airflow-net
      depends_on:
        northwind-db:
          condition: service_healthy
        redis:
          condition: service_healthy

  # Веб-интерфейс Airflow
  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8080/health || exit 1"]
      interval: 10s
      retries: 5
      timeout: 10s
    depends_on:
      - airflow-init
    environment:
      <<: *airflow-env
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: "${AIRFLOW_DAGS_ARE_PAUSED_AT_CREATION}"
      AIRFLOW__CORE__LOAD_EXAMPLES: "${AIRFLOW_LOAD_EXAMPLES}"
      AIRFLOW__API__AUTH_BACKEND: "${AIRFLOW_AUTH_BACKEND}"
      DBT_PROFILES_DIR: /usr/app/.dbt
      AIRFLOW__WEBSERVER__BASE_URL: "http://localhost:8081"
    ports:
      - "8081:8080"
    command: webserver
    restart: always
    user: "50000:50000"
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./dbt:/usr/app         # ⬅ dbt проект
    networks:
      - airflow-net
    mem_limit: 1500m

  # Планировщик Airflow
  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    healthcheck:
      test: ["CMD-SHELL", "airflow jobs check --job-type SchedulerJob || exit 1"]
      interval: 10s
      retries: 5
      timeout: 10s
    depends_on:
      - airflow-init
    environment:
      <<: *airflow-env
      DBT_PROFILES_DIR: /usr/app/.dbt
    user: "50000:50000"
    command: scheduler
    restart: always
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./dbt:/usr/app         # ⬅ dbt проект
    networks:
      - airflow-net
    mem_limit: 1500m

  # Рабочие процессы Airflow
  airflow-worker:
    build:
      context: .
      dockerfile: Dockerfile
    depends_on:
      - airflow-init
    environment:
      <<: *airflow-env
      DBT_PROFILES_DIR: /usr/app/.dbt
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: ${DB_NAME}
      DB_HOST: ${DB_HOST}
      DB_PORT: ${DB_PORT}
    user: "50000:50000"
    command: celery worker
    restart: always
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - ./dbt:/usr/app         # ⬅ dbt проект
    networks:
      - airflow-net
    mem_limit: 1500m

  # Redis для очередей задач Airflow
  redis:
    image: redis:latest
    ports:
      - "${REDIS_PORT}:6379"
    networks:
      - airflow-net
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 5
    restart: always
    command: ["redis-server", "--replicaof", "no", "one"]

  # PostgreSQL — основная база данных
  northwind-db:
    image: postgres:15
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
      PGDATA: /var/lib/postgresql/data/pgdata
      POSTGRES_INITDB_ARGS: "--auth-local=trust --auth-host=md5"
    volumes:
      - pgdata:/var/lib/postgresql/data/pgdata
      - ./init-db:/docker-entrypoint-initdb.d:ro
    networks:
      - airflow-net
    ports:
      - "5433:5432"
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${DB_USER} -d ${DB_NAME}"]
      interval: 5s
      timeout: 30s
      retries: 5
    mem_limit: 1000m

  # DBT — для трансформаций данных и формирования витрин
  dbt:
    image: ghcr.io/dbt-labs/dbt-postgres:1.7.9
    container_name: dbt
    entrypoint: [ "tail", "-f", "/dev/null" ]
    working_dir: /usr/app
    volumes:
    # Папка с проектом dbt (включая dbt_project.yml и models)
      - ./dbt:/usr/app
    # Директория с профилями dbt
      - ./dbt/.dbt:/usr/app/.dbt
    networks:
      - airflow-net
    environment:
      DBT_PROFILES_DIR: /usr/app/.dbt
      DB_USER: ${DB_USER}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_NAME: ${DB_NAME}
      DB_HOST: ${DB_HOST}
      DB_PORT: ${DB_PORT}
    depends_on:
      - northwind-db

  # PostgreSQL — метаданные Metabase (дашборды, настройки, пользователи)
  metabase-db:
    image: postgres:15
    env_file:
      - .env
    environment:
      POSTGRES_USER: ${MB_DB_USER}
      POSTGRES_PASSWORD: ${MB_DB_PASSWORD}
      POSTGRES_DB: ${MB_DB_NAME}
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - metabase_pgdata:/var/lib/postgresql/data/pgdata
    networks:
      - airflow-net
    ports:
      - "5434:5432"
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${MB_DB_USER:-metabase} -d ${MB_DB_NAME:-metabase}"]
      interval: 5s
      timeout: 30s
      retries: 5

  # Metabase — BI-платформа для визуализации данных
  metabase:
    image: metabase/metabase:latest
    env_file:
      - .env
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3000/ || exit 1"]
      interval: 10s
      retries: 5
      timeout: 10s
    container_name: airflow-metabase-1
    ports:
      - "3000:3000"
    environment:
      # Подключение к отдельной БД для метаданных Metabase (дашборды, вопросы, настройки)
      MB_DB_TYPE: postgres
      MB_DB_DBNAME: ${MB_DB_NAME}
      MB_DB_PORT: 5432
      MB_DB_USER: ${MB_DB_USER}
      MB_DB_PASS: ${MB_DB_PASSWORD}
      MB_DB_HOST: metabase-db
      JAVA_TOOL_OPTIONS: "-Xms512m -Xmx1500m"   # ограничение JVM
      MB_JETTY_MAXTHREADS: "50"                 # снижает расход памяти
    mem_limit: 2g
    networks:
      - airflow-net
    depends_on:
      metabase-db:
        condition: service_healthy


        # Metabase — БД для метаданных (дашборды, вопросы, настройки)
# Используется контейнер metabase-db, не northwind-db

